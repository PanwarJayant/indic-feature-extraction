{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ce773ed4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Requirement already satisfied: sentence-transformers in /Users/saivarunreddybhavanam/miniforge3/envs/data-science/lib/python3.9/site-packages (2.2.2)\n",
      "Requirement already satisfied: nltk in /Users/saivarunreddybhavanam/miniforge3/envs/data-science/lib/python3.9/site-packages (from sentence-transformers) (3.6.7)\n",
      "Requirement already satisfied: tqdm in /Users/saivarunreddybhavanam/miniforge3/envs/data-science/lib/python3.9/site-packages (from sentence-transformers) (4.62.3)\n",
      "Requirement already satisfied: torch>=1.6.0 in /Users/saivarunreddybhavanam/miniforge3/envs/data-science/lib/python3.9/site-packages (from sentence-transformers) (1.10.1)\n",
      "Requirement already satisfied: scipy in /Users/saivarunreddybhavanam/miniforge3/envs/data-science/lib/python3.9/site-packages (from sentence-transformers) (1.7.3)\n",
      "Requirement already satisfied: huggingface-hub>=0.4.0 in /Users/saivarunreddybhavanam/miniforge3/envs/data-science/lib/python3.9/site-packages (from sentence-transformers) (0.10.1)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.6.0 in /Users/saivarunreddybhavanam/miniforge3/envs/data-science/lib/python3.9/site-packages (from sentence-transformers) (4.24.0)\n",
      "Requirement already satisfied: numpy in /Users/saivarunreddybhavanam/miniforge3/envs/data-science/lib/python3.9/site-packages (from sentence-transformers) (1.22.1)\n",
      "Requirement already satisfied: sentencepiece in /Users/saivarunreddybhavanam/miniforge3/envs/data-science/lib/python3.9/site-packages (from sentence-transformers) (0.1.97)\n",
      "Requirement already satisfied: scikit-learn in /Users/saivarunreddybhavanam/miniforge3/envs/data-science/lib/python3.9/site-packages (from sentence-transformers) (1.0.2)\n",
      "Requirement already satisfied: torchvision in /Users/saivarunreddybhavanam/miniforge3/envs/data-science/lib/python3.9/site-packages (from sentence-transformers) (0.14.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /Users/saivarunreddybhavanam/miniforge3/envs/data-science/lib/python3.9/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (21.3)\n",
      "Requirement already satisfied: requests in /Users/saivarunreddybhavanam/miniforge3/envs/data-science/lib/python3.9/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (2.27.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/saivarunreddybhavanam/miniforge3/envs/data-science/lib/python3.9/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (4.0.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/saivarunreddybhavanam/miniforge3/envs/data-science/lib/python3.9/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (6.0)\n",
      "Requirement already satisfied: filelock in /Users/saivarunreddybhavanam/miniforge3/envs/data-science/lib/python3.9/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (3.8.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/saivarunreddybhavanam/miniforge3/envs/data-science/lib/python3.9/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (2022.1.18)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /Users/saivarunreddybhavanam/miniforge3/envs/data-science/lib/python3.9/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.11.5)\n",
      "Requirement already satisfied: click in /Users/saivarunreddybhavanam/miniforge3/envs/data-science/lib/python3.9/site-packages (from nltk->sentence-transformers) (8.0.3)\n",
      "Requirement already satisfied: joblib in /Users/saivarunreddybhavanam/miniforge3/envs/data-science/lib/python3.9/site-packages (from nltk->sentence-transformers) (1.1.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/saivarunreddybhavanam/miniforge3/envs/data-science/lib/python3.9/site-packages (from scikit-learn->sentence-transformers) (3.0.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /Users/saivarunreddybhavanam/miniforge3/envs/data-science/lib/python3.9/site-packages (from torchvision->sentence-transformers) (9.0.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /Users/saivarunreddybhavanam/miniforge3/envs/data-science/lib/python3.9/site-packages (from packaging>=20.9->huggingface-hub>=0.4.0->sentence-transformers) (3.0.6)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /Users/saivarunreddybhavanam/miniforge3/envs/data-science/lib/python3.9/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2.0.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/saivarunreddybhavanam/miniforge3/envs/data-science/lib/python3.9/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/saivarunreddybhavanam/miniforge3/envs/data-science/lib/python3.9/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (1.26.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/saivarunreddybhavanam/miniforge3/envs/data-science/lib/python3.9/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (3.1)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.3\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m22.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip3 install sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ec30bcb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000\n",
      "100000\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "model = SentenceTransformer('sentence-transformers/LaBSE')\n",
    "import codecs\n",
    "import numpy as np\n",
    "arr= []\n",
    "\n",
    "f = codecs.open(\"en-hi_dump_matras/dumpen_lakh.txt\", \"r\", \"utf-8\")\n",
    "englishSentences = f.readlines()\n",
    "f.close()\n",
    "\n",
    "g = codecs.open(\"en-hi_dump_matras/dumphi_lakh_matras.txt\", \"r\", \"utf-8\")\n",
    "teluguSentences = g.readlines()\n",
    "g.close()\n",
    "\n",
    "teluguSentencesSmallerSet = teluguSentences\n",
    "englishSentencesSmallerSet = englishSentences\n",
    "\n",
    "print(len(teluguSentencesSmallerSet))\n",
    "print(len(englishSentencesSmallerSet))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d2ea9826",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len (teluguSentencesSmallerSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "94424c88",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "similarityScores = []\n",
    "n = len(teluguSentences)\n",
    "print(n)\n",
    "for i in range(0,n):\n",
    "    l1 = teluguSentencesSmallerSet[i]\n",
    "    l2 = englishSentencesSmallerSet[i]\n",
    "    \n",
    "    emb1 = model.encode([l1])[0].reshape(1,-1)\n",
    "    \n",
    "    emb2 = model.encode([l2])[0].reshape(1,-1)\n",
    "    \n",
    "    score = cosine_similarity(emb1, emb2)[0,0]\n",
    "    similarityScores.append(score)\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5af883ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100000"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(similarityScores) #Batch size en-hi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "49b1a925",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9680928"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(similarityScores) #max of en-hi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "39b9bd77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.0723961"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(similarityScores) #min en-hi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6714a7a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('labse_cosine_en_hi_matras_100000.txt', 'w') as file:\n",
    "    file.write('\\n'.join(str(a) for a in similarityScores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6eb4b26a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len: 1000\n"
     ]
    }
   ],
   "source": [
    "with open(\"bleu-trans_te(en1)_en_0_1000.txt.txt\",\"r\") as f:\n",
    "    print(\"len:\", len(f.readlines()))  # This would give length of files.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d4153b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
